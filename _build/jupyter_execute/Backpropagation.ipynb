{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjdzYsqRqKuI"
   },
   "source": [
    "# Backpropagation\n",
    "Backpropagation adalah sebuah algoritma yang digunakan dalam jaringan saraf tiruan (neural network) untuk menghitung gradien dari fungsi biaya (cost function) terhadap parameter-parameter yang ada dalam jaringan tersebut. Algoritma ini digunakan dalam proses pelatihan (training) jaringan saraf tiruan dengan mengoptimalkan parameter-parameter tersebut.\n",
    "\n",
    "Proses backpropagation terdiri dari dua tahap: tahap maju (forward pass) dan tahap mundur (backward pass).\n",
    "\n",
    "Pada tahap maju, input data diberikan kepada jaringan saraf tiruan dan diteruskan melalui setiap lapisan (layer) jaringan, dari lapisan input ke lapisan output. Selama tahap ini, nilai output dari setiap neuron di setiap lapisan dihitung menggunakan fungsi aktivasi yang telah ditentukan.\n",
    "\n",
    "Setelah tahap maju selesai, tahap mundur dimulai. Pada tahap ini, gradien dari fungsi biaya terhadap setiap parameter dalam jaringan dihitung menggunakan aturan rantai (chain rule) dari kalkulus. Gradien ini menunjukkan sejauh mana perubahan pada parameter-parameter tersebut akan mempengaruhi nilai fungsi biaya. Gradien ini diteruskan mundur melalui jaringan, dari lapisan output ke lapisan input.\n",
    "\n",
    "Setelah gradien dihitung, algoritma optimisasi seperti gradien turun (gradient descent) dapat digunakan untuk memperbarui parameter-parameter jaringan berdasarkan gradien tersebut. Tujuan utama dari backpropagation adalah untuk menemukan nilai-nilai parameter yang meminimalkan fungsi biaya, sehingga jaringan dapat melakukan prediksi atau klasifikasi dengan akurasi yang tinggi.\n",
    "\n",
    "Dengan menggunakan backpropagation, jaringan saraf tiruan dapat belajar dan menyesuaikan bobot dan biasnya secara otomatis selama proses pelatihan. Ini memungkinkan jaringan saraf untuk mempelajari pola-pola yang terdapat dalam data pelatihan dan menghasilkan prediksi yang lebih baik pada data yang belum pernah dilihat sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_YMcphSxvwwb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbXhAJYdpRNg",
    "outputId": "b9331c51-279b-4a1f-ae7f-1e6d547a609e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x1   x2    y\n",
      "0  0.2  0.4  0.2\n",
      "1  0.4  0.3  0.1\n",
      "2  0.3  0.2  0.1\n",
      "3  0.2  0.5  0.3\n",
      "Fitur (X):\n",
      "[[0.2 0.4]\n",
      " [0.4 0.3]\n",
      " [0.3 0.2]\n",
      " [0.2 0.5]]\n",
      "Target (y):\n",
      "[[0.2]\n",
      " [0.1]\n",
      " [0.1]\n",
      " [0.3]]\n"
     ]
    }
   ],
   "source": [
    "# Baca file Excel\n",
    "data = {'x1': [0.2, 0.4, 0.3, 0.2],\n",
    "        'x2': [0.4, 0.3, 0.2, 0.5],\n",
    "        'y': [0.2, 0.1, 0.1, 0.3]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "data_array = df.values\n",
    "\n",
    "# Mengambil fitur X\n",
    "X = data_array[:, :-1]\n",
    "\n",
    "# Mengambil target y\n",
    "y = data_array[:, -1:]\n",
    "\n",
    "print(\"Fitur (X):\")\n",
    "print(X)\n",
    "print(\"Target (y):\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YZFHL8NIpVMx"
   },
   "outputs": [],
   "source": [
    "# Fungsi aktivasi sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivatif dari fungsi sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aMA46VNxpb-1"
   },
   "outputs": [],
   "source": [
    "# Kelas untuk jaringan saraf tiruan\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Inisialisasi bobot secara acak\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Propagasi maju (menghitung nilai output)\n",
    "        self.hidden = sigmoid(np.dot(X, self.weights1))  # Menghitung nilai hidden layer\n",
    "        self.output = sigmoid(np.dot(self.hidden, self.weights2))  # Menghitung nilai output layer\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        # Hitung gradien dan perbarui bobot\n",
    "        self.error = y - self.output  # Menghitung error\n",
    "        self.delta_output = self.error * sigmoid_derivative(self.output)  # Menghitung delta output layer\n",
    "        self.hidden_error = self.delta_output.dot(self.weights2.T)  # Menghitung error hidden layer\n",
    "        self.delta_hidden = self.hidden_error * sigmoid_derivative(self.hidden)  # Menghitung delta hidden layer\n",
    "        \n",
    "        # Perbarui bobot menggunakan metode backpropagation\n",
    "        self.weights2 += self.hidden.T.dot(self.delta_output) * learning_rate  # Perbarui bobot output layer\n",
    "        self.weights1 += X.T.dot(self.delta_hidden) * learning_rate  # Perbarui bobot hidden layer\n",
    "    \n",
    "    def train(self, X, y, iterasi, learning_rate):\n",
    "        for _ in range(iterasi):\n",
    "            self.forward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.forward(X)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3cw95UxpfQr",
    "outputId": "da793d4b-4228-4d38-86bd-41d6b878e5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil prediksi:\n",
      "[0.2 0.4] -> [0.54285168]\n",
      "[0.4 0.3] -> [0.54254931]\n",
      "[0.3 0.2] -> [0.55147115]\n",
      "[0.2 0.5] -> [0.53720151]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi jaringan saraf tiruan\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "iterasi = 4\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Melatih jaringan saraf tiruan\n",
    "nn.train(X, y, iterasi, learning_rate)\n",
    "\n",
    "# Melakukan prediksi\n",
    "print(\"Hasil prediksi:\")\n",
    "for i in range(len(X)):\n",
    "    output = nn.predict(X[i])\n",
    "    print(X[i], \"->\", output)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}